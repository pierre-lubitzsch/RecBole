use_gpu: True
# seed: set manually via command line --seed argument
state: INFO
reproducibility: True
data_path: 'dataset/'
show_progress: True

# Dataset
model: DNNTSP
task_type: NBR  # Required for next basket recommendation
benchmark_filename: ~
MAX_NBR_HISTORY_BASKETS: 50  # Maximum number of historical baskets to retain
MAX_NBR_BASKET_SIZE: 100  # Maximum size of each basket (-1 for unlimited)
MIN_NBR_BASKET_COUNT: 4  # Minimum basket count per user (matching original)
# NEXT_BASKET_JSON is automatically constructed as {dataset}_merged.json
loss_type: custom  # Using custom loss (MultiLabelSoftMarginLoss)

train_neg_sample_args: ~
valid_neg_sample_args: ~
test_neg_sample_args: ~

# Dataloader & Eval
# NextBasketDataset uses temporal leave-one-out split by default
eval_args:
  split: {'RS':[1,1,1]}
  group_by: ~
  order: TO  # Temporal ordering
  mode: full
train_batch_size: 64  # Matching original: batch_size=64
eval_batch_size: 64
metrics: ['Recall', 'NDCG', 'Hit']
topk: [10, 20]
valid_metric: Recall@10
valid_metric_bigger: True

# Model hyper-parameters
# Matching original DNNTSP implementation settings
embedding_size: 32  # Matching original: item_embed_dim=32

# Training
# Matching original train_main.py default hyperparameters:
# - epochs: 40
# - learning_rate: 0.001
# - optimizer: Adam
# - weight_decay: 0
epochs: 40
learner: adam
learning_rate: 0.001  # Matching original
weight_decay: 0.0  # Matching original (no L2 penalty)
stopping_step: 100  # Set high to avoid early stopping (can be adjusted)
clip_grad_norm: ~

# Optional: Customize field names if different from NextBasketDataset defaults
# DNNTSP_HISTORY_ITEMS_FIELD: 'history_item_matrix'
# DNNTSP_HISTORY_LENGTH_FIELD: 'history_basket_length'
# DNNTSP_HISTORY_ITEM_LENGTH_FIELD: 'history_item_length_per_basket'
# DNNTSP_TARGET_ITEMS_FIELD: 'target_item_list'
# DNNTSP_TARGET_LENGTH_FIELD: 'target_item_length'

# Notes:
# 1. The model uses MultiLabelSoftMarginLoss (matching original 'multi_label_soft_loss')
# 2. Graph construction is done on-the-fly from basket sequences
# 3. Edge weights are computed based on item co-occurrence in baskets
# 4. The model requires NextBasketDataset format with task_type='NBR'
# 5. To use temporal split (as in original), data should be in temporal order

# Example usage:
# python run_recbole.py --model=DNNTSP --dataset=instacart --config_files=config_dnntsp.yaml --seed=2

